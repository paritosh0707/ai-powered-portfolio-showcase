export const blogPosts = [
  {
    id: 1,
    title: "Building RAG Systems That Actually Work",
    excerpt: "A deep dive into retrieval-augmented generation architectures and how to optimize them for production use cases.",
    image: "src/static/demo3.png",
    date: "April 15, 2025",
    readTime: "12 min read",
    tags: ["LLMs", "RAG", "NLP"],
    slug: "building-rag-systems"
  },
  {
    id: 2,
    title: "Fine-tuning LLMs Without Breaking the Bank",
    excerpt: "Practical strategies for efficiently fine-tuning large language models with parameter-efficient techniques like LoRA and QLoRA.",
    image: "placeholder.svg",
    date: "March 24, 2025",
    readTime: "9 min read",
    tags: ["LLMs", "Fine-tuning", "PEFT"],
    slug: "fine-tuning-llms-efficiently"
  },
  {
    id: 3,
    title: "MLOps Best Practices for LLM Applications",
    excerpt: "How to build robust MLOps pipelines specifically designed for deploying and monitoring LLM-based applications.",
    image: "placeholder.svg",
    date: "February 10, 2025",
    readTime: "15 min read",
    tags: ["MLOps", "LLMs", "Production"],
    slug: "mlops-best-practices"
  },
  {
    id: 4,
    title: "MLOps Best Practices for LLM Applications",
    excerpt: "How to build robust MLOps pipelines specifically designed for deploying and monitoring LLM-based applications.",
    image: "placeholder.svg",
    date: "February 10, 2025",
    readTime: "15 min read",
    tags: ["MLOps", "LLMs", "Production"],
    slug: "mlops-best-practices"
  },
  {
    id: 5,
    title: "Building RAG Systems That Actually Work",
    excerpt: "A deep dive into retrieval-augmented generation architectures and how to optimize them for production use cases.",
    image: "src/static/demo3.png",
    date: "April 15, 2025",
    readTime: "12 min read",
    tags: ["LLMs", "RAG", "NLP"],
    slug: "building-rag-systems"
  },
  {
    id: 6,
    title: "Fine-tuning LLMs Without Breaking the Bank",
    excerpt: "Practical strategies for efficiently fine-tuning large language models with parameter-efficient techniques like LoRA and QLoRA.",
    image: "placeholder.svg",
    date: "March 24, 2025",
    readTime: "9 min read",
    tags: ["LLMs", "Fine-tuning", "PEFT"],
    slug: "fine-tuning-llms-efficiently"
  },
  {
    id: 7,
    title: "MLOps Best Practices for LLM Applications",
    excerpt: "How to build robust MLOps pipelines specifically designed for deploying and monitoring LLM-based applications.",
    image: "placeholder.svg",
    date: "February 10, 2025",
    readTime: "15 min read",
    tags: ["MLOps", "LLMs", "Production"],
    slug: "mlops-best-practices"
  },
  {
    id: 8,
    title: "MLOps Best Practices for LLM Applications",
    excerpt: "How to build robust MLOps pipelines specifically designed for deploying and monitoring LLM-based applications.",
    image: "placeholder.svg",
    date: "February 10, 2025",
    readTime: "15 min read",
    tags: ["MLOps", "LLMs", "Production"],
    slug: "mlops-best-practices"
  }
]; 